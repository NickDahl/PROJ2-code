---
title: "Project2"
author: "Nick Dahl"
date: "11/8/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
# Load the necessary packages
library(GGally)
library(ggplot2)
library(caret)
library(corrplot)
library(hrbrthemes)
library(gridExtra)
library(e1071)
library(kernlab)
library(Metrics)
```


```{r}
# Read in the image data sets
x1 <- read.table("image_data/imagem1.txt")
x2 <- read.table("image_data/imagem2.txt")
x3 <- read.table("image_data/imagem3.txt")

# Reassign proper column names
colnames(x1) <- colnames(x2) <- colnames(x3) <- 
  c("ycoord", "xcoord", "label", "NDAI", "SD", "CORR", 
    "DF", "CF", "BF", "AF", "AN")
```

```{r}
# Create subsamples for exploratory plots
x1t <- x1[sample(nrow(x1), 10000), ]
x2t <- x2[sample(nrow(x2), 10000), ]
x3t <- x3[sample(nrow(x3), 10000), ]
```

Part 1b: Summarize the data

```{r}
# % of pixels for different classes by image
print(paste0("Percentage of image 1 that is cloudy: ", 
             round(sum(x1$label == 1) / nrow(x1) * 100, 2), "%"))
print(paste0("Percentage of image 1 that is not cloudy: ", 
             round(sum(x1$label == -1) / nrow(x1) * 100, 2), "%"))
print(paste0("Percentage of image 1 that is unlabeled: ", 
             round(sum(x1$label == 0) / nrow(x1) * 100, 2), "%"))

# Same for second image
print(paste0("Percentage of image 2 that is cloudy: ", 
             round(sum(x2$label == 1) / nrow(x1) * 100, 2), "%"))
print(paste0("Percentage of image 2 that is not cloudy: ", 
             round(sum(x2$label == -1) / nrow(x1) * 100, 2), "%"))
print(paste0("Percentage of image 2 that is unlabeled: ", 
             round(sum(x2$label == 0) / nrow(x1) * 100, 2), "%"))

# Same for third image
print(paste0("Percentage of image 3 that is cloudy: ", 
             round(sum(x3$label == 1) / nrow(x1) * 100, 2), "%"))
print(paste0("Percentage of image 3 that is not cloudy: ", 
             round(sum(x3$label == -1) / nrow(x1) * 100, 2), "%"))
print(paste0("Percentage of image 3 that is unlabeled: ", 
             round(sum(x3$label == 0) / nrow(x1) * 100, 2), "%"))

# General summary plots
ggpairs(x1[1:2000, 3:11])
ggpairs(x2[1:2000, 3:11])
ggpairs(x3[1:2000, 3:11])
```

```{r}
# Color Brewer palette to make plots
ggplot(x1, aes(xcoord, ycoord, fill= label)) + 
  geom_tile() +
  scale_fill_distiller(palette = "RdPu") +
  theme_ipsum() + 
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
        panel.background = element_blank(),
        axis.line = element_line(colour = "black")) + 
  scale_x_continuous(expand = c(0, 0)) +
  scale_y_continuous(expand = c(0, 0)) +
  theme(panel.grid = element_blank(),
        panel.border = element_blank()) + 
  labs(title = "Map of Labeled Regions in Image 1", x = "X-Coordinate",
       y = "Y-Coordinate")

# Show representation of smaller portion of the plot
x1_sub <- x1[x1$xcoord < quantile(x1$xcoord, .6) & 
               x1$xcoord > quantile(x1$xcoord, .4) & 
               x1$ycoord < quantile(x1$ycoord, .6) & 
               x1$ycoord > quantile(x1$ycoord, .4), ]

ggplot(x1_sub, aes(xcoord, ycoord, fill= label)) + 
  geom_tile() +
  scale_fill_distiller(palette = "RdPu") +
  theme_ipsum() + 
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
        panel.background = element_blank(),
        axis.line = element_line(colour = "black")) + 
  scale_x_continuous(expand = c(0, 0)) +
  scale_y_continuous(expand = c(0, 0)) +
  theme(panel.grid = element_blank(),
        panel.border = element_blank()) + 
  labs(title = "Map of Labeled Regions in Image 1", x = "X-Coordinate",
       y = "Y-Coordinate")

# Image 2
ggplot(x2, aes(xcoord, ycoord, fill= label)) + 
  geom_tile() +
  scale_fill_distiller(palette = "RdPu") +
  theme_ipsum() + 
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
        panel.background = element_blank(),
        axis.line = element_line(colour = "black")) + 
  scale_x_continuous(expand = c(0, 0)) +
  scale_y_continuous(expand = c(0, 0)) +
  theme(panel.grid = element_blank(),
        panel.border = element_blank()) + 
  labs(title = "Map of Labeled Regions in Image 2", x = "X-Coordinate",
       y = "Y-Coordinate")

# Image 3
ggplot(x3, aes(xcoord, ycoord, fill= label)) + 
  geom_tile() +
  scale_fill_distiller(palette = "RdPu") +
  theme_ipsum() + 
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
        panel.background = element_blank(),
        axis.line = element_line(colour = "black")) + 
  scale_x_continuous(expand = c(0, 0)) +
  scale_y_continuous(expand = c(0, 0)) +
  theme(panel.grid = element_blank(),
        panel.border = element_blank()) + 
  labs(title = "Map of Labeled Regions in Image 3", x = "X-Coordinate",
       y = "Y-Coordinate")
```

Let's start looking for some correlations

```{r}
# Look at each correlation matrix
corrplot.mixed(cor(x1t), order = 'hclust')
corrplot.mixed(cor(x2t), order = 'hclust')
corrplot.mixed(cor(x3t), order = 'hclust')
```

```{r}
# Restore label as a factor 
x1t$label <- as.factor(x1t$label)

# Create boxplots of each group by predictors for distributional understanding
p1 <- ggplot(x1t, aes(group = label, NDAI)) +
  geom_boxplot() + 
  theme_ipsum() + 
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
        panel.background = element_blank(), 
        axis.line = element_line(colour = "black")) + 
  theme(panel.grid = element_blank(),
        panel.border = element_blank()) + 
  labs(title = "NDAI by Label", x = "", y = "") + 
  theme(plot.title = element_text(size=10))

p2 <- ggplot(x1t, aes(group = label, SD)) +
  geom_boxplot() + 
  theme_ipsum() + 
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
        panel.background = element_blank(),
        axis.line = element_line(colour = "black")) + 
  theme(panel.grid = element_blank(),
        panel.border = element_blank()) + 
  labs(title = "SD by Label", x = "", y = "") + 
  theme(plot.title = element_text(size=10))

p3 <- ggplot(x1t, aes(group = label, CORR)) +
  geom_boxplot() + 
  theme_ipsum() + 
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
        panel.background = element_blank(), 
        axis.line = element_line(colour = "black")) + 
  theme(panel.grid = element_blank(),
        panel.border = element_blank()) + 
  labs(title = "CORR by Label", x = "", y = "") + 
  theme(plot.title = element_text(size=10))

p4 <- ggplot(x1t, aes(group = label, DF)) +
  geom_boxplot() + 
  theme_ipsum() + 
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
        panel.background = element_blank(), 
        axis.line = element_line(colour = "black")) + 
  theme(panel.grid = element_blank(),
        panel.border = element_blank()) + 
  labs(title = "DF by Label", x = "", y = "") + 
  theme(plot.title = element_text(size=10))

p5 <- ggplot(x1t, aes(group = label, CF)) +
  geom_boxplot() + 
  theme_ipsum() + 
  theme(panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank(),
        panel.background = element_blank(), 
        axis.line = element_line(colour = "black")) + 
  theme(panel.grid = element_blank(),
        panel.border = element_blank()) + 
  labs(title = "CF by Label", x = "", y = "") + 
  theme(plot.title = element_text(size=10))

p6 <- ggplot(x1t, aes(group = label, BF)) +
  geom_boxplot() + 
  theme_ipsum() + 
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
        panel.background = element_blank(), 
        axis.line = element_line(colour = "black")) + 
  theme(panel.grid = element_blank(),
        panel.border = element_blank()) + 
  labs(title = "BF by Label", x = "", y = "") + 
  theme(plot.title = element_text(size=10))

p7 <- ggplot(x1t, aes(group = label, AF)) +
  geom_boxplot() + 
  theme_ipsum() + 
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
        panel.background = element_blank(), 
        axis.line = element_line(colour = "black")) + 
  theme(panel.grid = element_blank(),
        panel.border = element_blank()) + 
  labs(title = "AF by Label", x = "", y = "") + 
  theme(plot.title = element_text(size=10))

p8 <- ggplot(x1t, aes(group = label, AN)) +
  geom_boxplot() + 
  theme_ipsum() + 
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
        panel.background = element_blank(), 
        axis.line = element_line(colour = "black")) + 
  theme(panel.grid = element_blank(),
        panel.border = element_blank()) + 
  labs(title = "AN by Label", x = "", y = "") + 
  theme(plot.title = element_text(size=10))

# Compile all plots and output
grid.arrange(p1, p2, p3, p4, nrow = 2)
grid.arrange(p5, p6, p7, p8, nrow = 2)
```


## Question 2

### Part a

Split the data into three sets: training, validation, and test

If we want to split the data, we may want to ensure that we have equal representation from each group, given that they are differentiated in terms of generative behavior. Alternately, we may want to ensure that the points are selected randomly across regions, which we can achieve by breaking the data down into blocks and sampling from each block:

https://arxiv.org/pdf/1906.02899.pdf (paper for reference)

60/20/20 split (training, validation, testing)

```{r}
# First, sample 60% from each of the images, then combine
samp1 <- sample(nrow(x1), .6 * nrow(x1))
samp2 <- sample(nrow(x2), .6 * nrow(x2))
samp3 <- sample(nrow(x3), .6 * nrow(x3))

x1_train <- x1[samp1, ]
x2_train <- x2[samp2, ]
x3_train <- x3[samp3, ]

# First potential training set
x1_train <- x1_train[, colnames(x1_train) != "textlabel"]
train1 <- rbind(x1_train, x2_train, x3_train)

x1 <- x1[, colnames(x1) != "textlabel"]
temp1 <- x1[-samp1, ]
temp2 <- x2[-samp2, ]
temp3 <- x3[-samp3, ]

samp1.2 <- sample(nrow(temp1), .5*nrow(temp1))
samp2.2 <- sample(nrow(temp2), .5*nrow(temp2))
samp3.2 <- sample(nrow(temp2), .5*nrow(temp3))

# First validation and test sets as well 
val1 <- rbind(temp1[samp1.2,], temp2[samp2.2,], temp3[samp3.2,])
test1 <- rbind(temp1[-samp1.2,], temp2[-samp2.2,], temp3[-samp3.2,])
```

```{r}
# Create a 25x25pixel grid across each image
image_1xseq <- seq(min(x1$xcoord), max(x1$xcoord), 25)
image_1yseq <- seq(min(x1$ycoord), max(x1$ycoord), 25)

image_2xseq <- seq(min(x2$xcoord), max(x2$xcoord), 25)
image_2yseq <- seq(min(x2$ycoord), max(x2$ycoord), 25)

image_3xseq <- seq(min(x3$xcoord), max(x3$xcoord), 25)
image_3yseq <- seq(min(x3$ycoord), max(x3$ycoord), 25)

# Loop through and create list of potential samples
image_list <- list()
for (i in 2:length(image_1xseq)) {
  for (j in 2:length(image_1yseq)) {
    df1_sub <- x1[x1$xcoord < image_1xseq[i] & 
                    x1$xcoord > image_1xseq[i-1] & 
                    x1$ycoord < image_1yseq[i] & 
                    x1$ycoord > image_1yseq[i-1], ]
    df2_sub <- x2[x2$xcoord < image_2xseq[i] & 
                    x2$xcoord > image_2xseq[i-1] & 
                    x2$ycoord < image_2yseq[i] & 
                    x2$ycoord > image_2yseq[i-1], ]
    df3_sub <- x3[x3$xcoord < image_3xseq[i] & 
                    x3$xcoord > image_3xseq[i-1] & 
                    x3$ycoord < image_3yseq[i] & 
                    x3$ycoord > image_3yseq[i-1], ]
    image_list[[length(image_list)+1]] <- df1_sub
    image_list[[length(image_list)+1]] <- df2_sub
    image_list[[length(image_list)+1]] <- df3_sub
    
  }
}

# Now sample for train/test/validation
samp1 <- sample(1:length(image_list), .6 * length(image_list))
train2_samps <- image_list[samp1]
train2 <- train2_samps[[1]]
for (i in 2:length(train2_samps)) {
  train2 <- train2[, colnames(train2) != "textlabel"]
  temp <- train2_samps[[i]]
  temp <- temp[, colnames(temp) != "textlabel"]
  train2 <- rbind(train2, temp)
}

temp1 <- image_list[-samp1]
samp1.2 <- sample(1:length(temp1), .5*length(temp1))

test2_samp <- temp1[samp1.2]
val2_samp <- temp1[-samp1.2]

test2 <- test2_samp[[1]]
val2 <- val2_samp[[1]]

for (i in 2:length(test2_samp)) {
  test2 <- test2[, colnames(test2) != "textlabel"]
  val2 <- val2[, colnames(val2) != "textlabel"]
  
  temp <- test2_samp[[i]]
  temp <- temp[, colnames(temp) != "textlabel"]
  test2 <- rbind(test2, temp)
  
  temp_val <- val2_samp[[i]]
  temp_val <- temp_val[, colnames(temp_val) != "textlabel"]
  val2 <- rbind(val2, temp_val)
}
```


```{r}
###########################################
# THIRD METHOD OF SAMPLING DATA - RETIRED #
###########################################

# # Second, sample equal rates of each type from each image, then combine
# image_1_pos <- x1[x1$label == 1, ]
# image_2_pos <- x2[x2$label == 1, ]
# image_3_pos <- x3[x3$label == 1, ]
# 
# image_1_neg <- x1[x1$label == -1, ]
# image_2_neg <- x2[x2$label == -1, ]
# image_3_neg <- x3[x3$label == -1, ]
# 
# image_1_un <- x1[x1$label == 0, ]
# image_2_un <- x2[x2$label == 0, ]
# image_3_un <- x3[x3$label == 0, ]
# 
# # First split up each of the postiive
# indices_1 <- sample(rep(1:3, times = c(.6 * nrow(image_1_pos),
# .2 * nrow(image_1_pos), 
#                                        .2 * nrow(image_1_pos))))
# pos_1_split <- split(image_1_pos, indices_1)
# 
# indices_2 <- sample(rep(1:3, times = c(.6 * nrow(image_2_pos), 
# .2 * nrow(image_2_pos), 
#                                        .2 * nrow(image_2_pos))))
# pos_2_split <- split(image_2_pos, indices_2)
# 
# indices_3 <- sample(rep(1:3, times = c(.6 * nrow(image_3_pos), 
# .2 * nrow(image_3_pos), 
#                                        .2 * nrow(image_3_pos))))
# pos_3_split <- split(image_3_pos, indices_3)
# 
# # Now do the same for negative
# indices_1 <- sample(rep(1:3, times = c(.6 * nrow(image_1_neg), 
# .2 * nrow(image_1_neg), 
#                                        .2 * nrow(image_1_neg))))
# neg_1_split <- split(image_1_neg, indices_1)
# 
# indices_2 <- sample(rep(1:3, times = c(.6 * nrow(image_2_neg),
# .2 * nrow(image_2_neg), 
#                                        .2 * nrow(image_2_neg))))
# neg_2_split <- split(image_2_neg, indices_2)
# 
# indices_3 <- sample(rep(1:3, times = c(.6 * nrow(image_3_neg), 
#.2 * nrow(image_3_neg), 
#                                        .2 * nrow(image_3_neg))))
# neg_3_split <- split(image_3_neg, indices_3)
# 
# # Finally, split across the non-labeled points
# indices_1 <- sample(rep(1:3, times = c(.6 * nrow(image_1_un), 
# .2 * nrow(image_1_un), 
#                                        .2 * nrow(image_1_un))))
# un_1_split <- split(image_1_un, indices_1)
# 
# indices_2 <- sample(rep(1:3, times = c(.6 * nrow(image_2_un), 
# .2 * nrow(image_2_un), 
#                                        .2 * nrow(image_2_un))))
# un_2_split <- split(image_2_neg, indices_2)
# 
# indices_3 <- sample(rep(1:3, times = c(.6 * nrow(image_3_un),
# .2 * nrow(image_3_un), 
#                                        .2 * nrow(image_3_un))))
# un_3_split <- split(image_3_un, indices_3)
# 
# # Then combine
# train2 <- rbind(pos_1_split$`1`, pos_2_split$`1`, pos_3_split$`1`,
#                 neg_1_split$`1`, neg_1_split$`1`, neg_1_split$`1`,
#                 un_1_split$`1`, un_1_split$`1`, un_1_split$`1`)
# 
# val2 <- rbind(pos_1_split$`2`, pos_2_split$`2`, pos_3_split$`2`,
#               neg_1_split$`2`, neg_1_split$`2`, neg_1_split$`2`,
#               un_1_split$`2`, un_1_split$`2`, un_1_split$`2`)
# 
# test2 <- rbind(pos_1_split$`3`, pos_2_split$`3`, pos_3_split$`3`,
#                neg_1_split$`3`, neg_1_split$`3`, neg_1_split$`3`,
#                un_1_split$`3`, un_1_split$`3`, un_1_split$`3`)
```

### Part b

Report the accuracy of a trivial classifier setting all labels to -1

```{r}
# Look at the accuracy of a trivial classifier for each
mean(train2$label == 0)
mean(test2$label == 0)
mean(val2$label == 0)
```
This will perform especially well in the case where most of the points share the label of the naive estimate.

### Part c

Important features: NDAI, CORR, and AN (at least for two of the images)

Run a PRComp

```{r}
# Consider a PCA 
pca_1 <- prcomp(train2[, c("DF", "CF", "BF", "AF", "AN")])

# Compile directional results
pca_results <- as.data.frame(pca_1$x)

# Transfer the labels
pca_results$label <- train2$label

# Create a plot to examine PCA directions and professional labels
ggplot(pca_results) + geom_point(aes(x = PC1, y = PC2, col = label)) + 
  labs(title = "First Two Principle Components of Radiance Angles") + 
  theme_ipsum() + 
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
        panel.background = element_blank(), 
        axis.line = element_line(colour = "black")) + 
  theme(panel.grid = element_blank(),
        panel.border = element_blank()) + 
  scale_fill_distiller(palette = "RdPu")

# Create a plot to look at third and fourth directions
ggplot(pca_results) + geom_point(aes(x = PC3, y = PC4, col = label)) 

# Perform PCA on the other non-radiance features
pca_2 <- prcomp(train2[, c("NDAI", "SD", "CORR")])
pca_2_results <- as.data.frame(pca_2$x)
pca_2_results$label <- train2$label

# See if there's anything significant here (no)
ggplot(pca_2_results) + geom_point(aes(x = PC1, y = PC2, col = label)) + 
  labs(title = "First Two Principle Components of Non-Radiance Angles") + 
  theme_ipsum() + 
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
        panel.background = element_blank(), 
        axis.line = element_line(colour = "black")) + 
  theme(panel.grid = element_blank(),
        panel.border = element_blank()) + 
  scale_fill_distiller(palette = "RdPu")

```

```{r}
# Plot DF against SD
ggplot(train2) + geom_point(aes(x = DF, y = SD, col = label)) + 
  labs(title = "Scatterplot of Labels across DF vs. SD") + 
  theme_ipsum() + 
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
        panel.background = element_blank(), 
        axis.line = element_line(colour = "black")) + 
  theme(panel.grid = element_blank(),
        panel.border = element_blank()) 

# Plot CORR against NDAI
ggplot(train2) + geom_point(aes(x = CORR, y = NDAI, col = label)) + 
  labs(title = "Scatterplot of Labels across CORR vs. NDAI") + 
  theme_ipsum() + 
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
        panel.background = element_blank(), 
        axis.line = element_line(colour = "black")) + 
  theme(panel.grid = element_blank(),
        panel.border = element_blank()) 

# Plot xcoord and ycoord against label
ggplot(train2) + geom_point(aes(x = xcoord, y = ycoord, col = label)) + 
  labs(title = "Scatterplot of Labels across XCoord vs. YCoord") + 
  theme_ipsum() + 
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
        panel.background = element_blank(), 
        axis.line = element_line(colour = "black")) + 
  theme(panel.grid = element_blank(),
        panel.border = element_blank()) 

```



### Part d

```{r}
# Write a function to return class accuracies
class_accuracy <- function(xfeatures, xlabels) {
  return(sum(diag(table(xfeatures, xlabels))) / length(xlabels))
}

# First pass at CVMaster function 
CVmaster <- function(classifier, features, labels, 
                     kfolds = 5, loss = class_accuracy) {
  # Iterate over each of the folds
  # Start by splitting the data
  indices <- sample(rep(1:kfolds, times = rep(1/kfolds * nrow(xfeatures), kfolds)))
  split_features <- split(features, indices)
  split_labels <- split(labels, indices)
  
  accuracies <- rep(NA, kfolds)
  
  for (i in 1:kfolds) {
    feat <- split_features[[i]]
    labs <- split_labels[[i]]
    
    classifier_labels <- classifier(feat, labs)
    accuracy <- loss(labs, classifier_labels)
    
    accuracies[i] <- accuracy
  }
  
  return(mean(accuracies))
}
```


## Part 4

Let's perform SVM

```{r}
# Combine sumsamples 
xt <- rbind(x1t, x2t, x3t)

# Take 80% for use
samps <- sample(nrow(xt), .8*nrow(xt))

# Separate training and testing 
xt_train <- xt[samps, ]
xt_test <- xt[-samps, ]

# Return each of the labels
xt_train_labels <- xt_train$label
xt_train <- xt_train[, names(xt_train) != "label"]
xt_test_labels <- xt_test$label
xt_test <- xt_test[, names(xt_test) != "label"]

################################################
# LABOR INTENSIVE CODE - UNCOMMENT AT OWN RISK #
# USED TO TUNE PARAMETERS COST AND GAMMA       #
################################################

# ctrl <- trainControl(method = "repeatedcv", repeats = 5, savePredictions = TRUE, 
#                      classProbs = TRUE)
# 
# svm.tune <- train(x = xt_train, y = xt_train_labels, method = "svmLinear", 
#                   tuneLength = 5, preProcess = c("center", "scale"), trControl = ctrl,
#                   ranges = list(gamma = seq(0,.2,.01), cost = 2^(2:9)),
#                   tunecon)
# 
# svm.tune
# 
# plot(svm.tune)


# x1t$label <- as.factor(x1t$label)
# data_use <- xt[sample(1:nrow(xt), 6000),]
# data_use$label <- as.factor(data_use$label)
# 
# tune_model <- tune(svm, label ~ ., data = data_use, 
#           ranges = list(gamma = 2^(-3:3), cost = 2^(0:9)),
#           tunecontrol = tune.control(sampling = "fix"))
# 
# summary(tune_model)
# 
# tune_model$performances$gamma <- as.factor(tune_model$performances$gamma)
# tune_model$performances$cost <- as.factor(tune_model$performances$cost)

# ggplot(tune_model$performances, aes(x = gamma, y = cost, fill = error)) + 
#   geom_tile() + 
#   labs(title = "Tuning across Gamma and Cost Parameters")

# Perform PCA on second training set
train_2.1 <- cbind(train2, pca_results[, c("PC1", "PC2")])

# Run PCA for first training set
pca_2 <- prcomp(train1[, c("DF", "CF", "BF", "AF", "AN")])
pca_results <- as.data.frame(pca_2$x)

train_1.1 <- cbind(train1, pca_results[, c("PC1", "PC2")])
train_1.1$label <- as.factor(train_1.1$label)

################################################
# LABOR INTENSIVE CODE - UNCOMMENT AT OWN RISK #
# USED TO CREATE FINAL SVM MODELS IN USE       #
################################################

# m2 <- svm(label ~ NDAI + SD + CORR + xcoord + ycoord + PC1 + PC2, data = train_2.1,
#           gamma = 1, cost = 4)
# 
# 
# m3 <- svm(label ~ NDAI + SD + CORR + xcoord + ycoord + PC1 + PC2, data = train_1.1,
#           gamma = 1, cost = 4)

# Perform PCA for test data to get columns as well
# pca_3 <- prcomp(test1[, c("DF", "CF", "BF", "AF", "AN")])
# test1 <- cbind(test1, as.data.frame(pca_3$x)[, c("PC1", "PC2")])
# 
# tunedModelY <- predict(m2, test1)
# actual_vals <- test1$label
# 
# table(actual_vals, tunedModelY)
# 
# tuned_2 <- predict(m3, test1)
# act_vals2 <- test1$label
# table(tuned_2, act_vals2)
```

Evaluation of these will be set to false, given that the models would need to be run above again for it to compile. Set eval = TRUE to generate visualizations.

```{r, eval = FALSE}
par(mfrow = c(2,2))
plot(m2, data_use, xcoord ~ ycoord, 
     slice = list(NDAI = quantile(data_use$NDAI, .75), 
                  SD = quantile(data_use$SD, .75),
                  CORR = quantile(data_use$CORR, .75),
                  DF = quantile(data_use$DF, .75),
                  CF = quantile(data_use$CF, .75),
                  BF = quantile(data_use$BF, .75),
                  AF = quantile(data_use$AF, .75),
                  AN = quantile(data_use$AN, .75)))

plot(m2, data_use, NDAI ~ SD, 
     slice = list(xcoord = quantile(data_use$xcoord, .25), 
                  ycoord = quantile(data_use$ycoord, .25),
                  CORR = mean(data_use$CORR),
                  DF = mean(data_use$DF),
                  CF = mean(data_use$CF),
                  BF = mean(data_use$BF),
                  AF = mean(data_use$AF),
                  AN = mean(data_use$AN)))

plot(m2, data_use, CORR ~ DF, 
     slice = list(NDAI = mean(data_use$NDAI), 
                  SD = mean(data_use$SD),
                  xcoord = median(data_use$xcoord),
                  ycoord = median(data_use$ycoord),
                  CF = mean(data_use$CF),
                  BF = mean(data_use$BF),
                  AF = mean(data_use$AF),
                  AN = mean(data_use$AN)))

test1$label <- as.factor(test1$label)
plot(m3, test1[sample(1:nrow(test1), 2000), ], xcoord ~ ycoord, 
     slice = list(NDAI = quantile(test1$NDAI, .75), 
                  SD = quantile(test1$SD, .75),
                  CORR = quantile(test1$CORR, .75),
                  DF = quantile(test1$DF, .75),
                  CF = quantile(test1$CF, .75),
                  BF = quantile(test1$BF, .75),
                  AF = quantile(test1$AF, .75),
                  AN = quantile(test1$AN, .75),
                  PC1 = quantile(test1$PC1, .75),
                  PC2 = quantile(test1$PC2, .75)))
```

```{r}
# Create trivially small SVM's to generate plot showing increase in runtime
runtime <- rep(NA, 9)

# First for a sample of 10 observations
start_time <- Sys.time()
svm(label ~., data = xt[sample(1:nrow(xt), 10),])
end_time <- Sys.time()
runtime[1] <- end_time - start_time

# Then for a sample of 100 observations
start_time <- Sys.time()
svm(label ~., data = xt[sample(1:nrow(xt), 100),])
end_time <- Sys.time()
runtime[2] <- end_time - start_time

# Next, 500 observations
start_time <- Sys.time()
svm(label ~., data = xt[sample(1:nrow(xt), 500),])
end_time <- Sys.time()
runtime[3] <- end_time - start_time

# 1,000 observations
start_time <- Sys.time()
svm(label ~., data = xt[sample(1:nrow(xt), 1000),])
end_time <- Sys.time()
runtime[4] <- end_time - start_time

# 1,500 observations
start_time <- Sys.time()
svm(label ~., data = xt[sample(1:nrow(xt), 1500),])
end_time <- Sys.time()
runtime[5] <- end_time - start_time

# 2,500 observations
start_time <- Sys.time()
svm(label ~., data = xt[sample(1:nrow(xt), 2500),])
end_time <- Sys.time()
runtime[6] <- end_time - start_time

# 5,000 observations
start_time <- Sys.time()
svm(label ~., data = xt[sample(1:nrow(xt), 5000),])
end_time <- Sys.time()
runtime[7] <- end_time - start_time

# 7,500 observations
start_time <- Sys.time()
svm(label ~., data = xt[sample(1:nrow(xt), 7500),])
end_time <- Sys.time()
runtime[8] <- end_time - start_time

# And finally, 10,000 observations
start_time <- Sys.time()
svm(label ~., data = xt[sample(1:nrow(xt), 10000),])
end_time <- Sys.time()
runtime[9] <- end_time - start_time

# Look at the plot
plot(x = c(10, 100, 500, 1000, 1500, 2500, 5000, 7500, 10000),
     y = runtime[1:9], main = "Runtime vs. Number of Samples for SVM", 
     type = "l", ylab = "Runtime (seconds)", xlab = "Number of Samples")
```



